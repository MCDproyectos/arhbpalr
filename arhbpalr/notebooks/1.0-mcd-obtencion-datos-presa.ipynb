{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **OBTENCIÓN DE DATOS DE LA PRESA ABELARDO L. RODRÍGUEZ**\n",
    "\n",
    "Este notebook obtiene los datos históricos de la capacidad hídrica de la Presa Abelardo L. Rodríguez desde el portal de Sonora Datos Abiertos mediante web scraping.\n",
    "\n",
    "**Salida:** `../data/raw/datos_presa_arlso.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T04:59:53.020293Z",
     "iopub.status.busy": "2025-10-16T04:59:53.019177Z",
     "iopub.status.idle": "2025-10-16T04:59:55.409568Z",
     "shell.execute_reply": "2025-10-16T04:59:55.409568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de datos: c:\\Users\\DELL\\Documents\\Areas\\MCD\\1S\\Ingeniería de Características\\ingesta de datos\\arhbpalr\\arhbpalr\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Definir rutas del proyecto siguiendo estructura Cookiecutter\n",
    "project_dir = Path.cwd().parent\n",
    "data_dir = project_dir / 'data' / 'raw'\n",
    "\n",
    "print(f\"Directorio de datos: {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diccionario de presas de Sonora\n",
    "\n",
    "Contiene las claves y nombres de todas las presas monitoreadas en Sonora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T04:59:55.451797Z",
     "iopub.status.busy": "2025-10-16T04:59:55.450791Z",
     "iopub.status.idle": "2025-10-16T04:59:55.454607Z",
     "shell.execute_reply": "2025-10-16T04:59:55.454607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presa objetivo: Presa Abelardo L. Rodríguez\n"
     ]
    }
   ],
   "source": [
    "# Diccionario de claves de presas en Sonora\n",
    "presas_sonora = {\n",
    "    \"LCDSO\": \"Presa Lázaro Cárdenas (La Angostura)\",\n",
    "    \"CHTSO\": \"Presa Cuauhtémoc\",\n",
    "    \"ARLSO\": \"Presa Abelardo L. Rodríguez\",\n",
    "    \"AOBSO\": \"Presa Álvaro Obregón (Oviáchic)\",\n",
    "    \"ARCSO\": \"Presa Adolfo Ruiz Cortines (Mocúzari)\",\n",
    "    \"PECSO\": \"Presa Plutarco Elías Calles (El Novillo)\",\n",
    "    \"AGZCH\": \"Presa Abraham González\",\n",
    "    \"PMOSO\": \"Presa Ing. Rodolfo Félix Valdés (El Molinito)\",\n",
    "    \"IRASO\": \"Presa Ignacio R. Alatorre\",\n",
    "    \"BICSO\": \"Presa Bicentenario\"\n",
    "}\n",
    "\n",
    "print(f\"Presa objetivo: {presas_sonora['ARLSO']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Web Scraping: obtener enlaces de datos\n",
    "\n",
    "Extraemos los enlaces de los archivos XLSX desde el portal de Sonora Datos Abiertos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T04:59:55.456612Z",
     "iopub.status.busy": "2025-10-16T04:59:55.456612Z",
     "iopub.status.idle": "2025-10-16T04:59:56.181052Z",
     "shell.execute_reply": "2025-10-16T04:59:56.181052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enlaces encontrados: 8\n",
      "1. hidrico_sonora_1941-1949.xlsx\n",
      "2. hidrico_sonora_1950-1959.xlsx\n",
      "3. hidrico_sonora_1970-1979.xlsx\n",
      "4. hidrico_sonora_1980-1989.xlsx\n",
      "5. hidrico_sonora_1990-1999.xlsx\n",
      "6. hidrico_sonora_2000-2009.xlsx\n",
      "7. hidrico_sonora_2010-2019.xlsx\n",
      "8. hidrico_sonora_2020-actualidad2024.xlsx\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get('https://datos.sonora.gob.mx/dataset/Recursos%20H%C3%ADdricos')\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "links_datasets = soup.find('section', id='dataset-resources').find_all('ul')\n",
    "\n",
    "# Extraer enlaces de capacidad hídrica\n",
    "links_cap = []\n",
    "for link in links_datasets[0].find_all('a', attrs={'target': \"_blank\"}):\n",
    "    if link.get('href') != '':\n",
    "        links_cap.append(link.get('href'))\n",
    "\n",
    "print(f\"Enlaces encontrados: {len(links_cap)}\")\n",
    "for i, link in enumerate(links_cap, 1):\n",
    "    print(f\"{i}. {link.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Descargar y convertir archivos XLSX a CSV\n",
    "\n",
    "Descargamos los archivos Excel y los convertimos a formato CSV temporal para procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T04:59:56.183056Z",
     "iopub.status.busy": "2025-10-16T04:59:56.183056Z",
     "iopub.status.idle": "2025-10-16T05:00:09.398413Z",
     "shell.execute_reply": "2025-10-16T05:00:09.398413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo creado: hidrico_sonora_1941-1949.csv\n",
      "✓ Archivo creado: hidrico_sonora_1950-1959.csv\n",
      "✓ Archivo creado: hidrico_sonora_1970-1979.csv\n",
      "✓ Archivo creado: hidrico_sonora_1980-1989.csv\n",
      "✓ Archivo creado: hidrico_sonora_1990-1999.csv\n",
      "✓ Archivo creado: hidrico_sonora_2000-2009.csv\n",
      "✓ Archivo creado: hidrico_sonora_2010-2019.csv\n",
      "✓ Archivo creado: hidrico_sonora_2020-actualidad2024.csv\n",
      "\n",
      "Total de archivos procesados: 8\n"
     ]
    }
   ],
   "source": [
    "# Crear directorio temporal para archivos CSV si no existe\n",
    "temp_dir = 'temp_csv'\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# Crear archivos CSV para cada uno\n",
    "paths = []\n",
    "for link in links_cap:\n",
    "    # Extraer el nombre del archivo del link y cambiar la extensión a .csv\n",
    "    file_name = link.split(\"/\")[-1].replace(\".xlsx\", \".csv\")\n",
    "    file_path = os.path.join(temp_dir, file_name)\n",
    "    \n",
    "    # Leer el archivo Excel desde el link y guardarlo como CSV\n",
    "    try:\n",
    "        df = pd.read_excel(link)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        paths.append(file_path)\n",
    "        print(f\"✓ Archivo creado: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ No se pudo procesar el link {link}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal de archivos procesados: {len(paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Consolidar todos los datos en un DataFrame\n",
    "\n",
    "Leemos todos los archivos CSV y los concatenamos en un solo DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:00:09.400480Z",
     "iopub.status.busy": "2025-10-16T05:00:09.400480Z",
     "iopub.status.idle": "2025-10-16T05:00:09.584882Z",
     "shell.execute_reply": "2025-10-16T05:00:09.584882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agregado: hidrico_sonora_1941-1949.csv\n",
      "Agregado: hidrico_sonora_1950-1959.csv\n",
      "Agregado: hidrico_sonora_1970-1979.csv\n",
      "Agregado: hidrico_sonora_1980-1989.csv\n",
      "Agregado: hidrico_sonora_1990-1999.csv\n",
      "Agregado: hidrico_sonora_2000-2009.csv\n",
      "Agregado: hidrico_sonora_2010-2019.csv\n",
      "Agregado: hidrico_sonora_2020-actualidad2024.csv\n",
      "\n",
      "Dimensiones totales: (202993, 3)\n",
      "Presas únicas encontradas: ['LCDSO' 'CHTSO' 'ARLSO' 'AOBSO' 'ARCSO' 'PECSO' 'AGZCH' 'PMOSO' 'IRASO'\n",
      " 'BICSO']\n"
     ]
    }
   ],
   "source": [
    "# Consolidar todos los datos\n",
    "df_cap = pd.DataFrame()\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path, names=[\"clave\", \"fecha\", \"almacenamiento_hm3\"], skiprows=1, header=None)\n",
    "    df_cap = pd.concat([df_cap, df], ignore_index=True)\n",
    "    print(f\"Agregado: {os.path.basename(path)}\")\n",
    "\n",
    "print(f\"\\nDimensiones totales: {df_cap.shape}\")\n",
    "print(f\"Presas únicas encontradas: {df_cap['clave'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Filtrar datos de la Presa Abelardo L. Rodríguez (ARLSO)\n",
    "\n",
    "Extraemos únicamente los registros correspondientes a la presa de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:00:09.586887Z",
     "iopub.status.busy": "2025-10-16T05:00:09.586887Z",
     "iopub.status.idle": "2025-10-16T05:00:09.683370Z",
     "shell.execute_reply": "2025-10-16T05:00:09.683370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros de la Presa ARLSO: 24631\n",
      "Rango de fechas: 1947-04-14 00:00:00 a 2024-09-19 00:00:00\n",
      "\n",
      "Primeros registros:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>almacenamiento_hm3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1947-04-14 00:00:00</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1947-04-15 00:00:00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1947-04-16 00:00:00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1947-04-17 00:00:00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1947-04-18 00:00:00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1947-04-19 00:00:00</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1947-04-20 00:00:00</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1947-04-21 00:00:00</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1947-04-22 00:00:00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1947-04-23 00:00:00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fecha almacenamiento_hm3\n",
       "0  1947-04-14 00:00:00               0.09\n",
       "1  1947-04-15 00:00:00               0.11\n",
       "2  1947-04-16 00:00:00               0.11\n",
       "3  1947-04-17 00:00:00               0.12\n",
       "4  1947-04-18 00:00:00               0.12\n",
       "5  1947-04-19 00:00:00               0.13\n",
       "6  1947-04-20 00:00:00               0.14\n",
       "7  1947-04-21 00:00:00               0.14\n",
       "8  1947-04-22 00:00:00               0.15\n",
       "9  1947-04-23 00:00:00               0.15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrar datos de ARLSO\n",
    "df_arlso = df_cap[df_cap[\"clave\"] == \"ARLSO\"].copy()\n",
    "\n",
    "# Limpiar y convertir tipos de datos\n",
    "# Reemplazar guiones o valores vacíos por NaN\n",
    "df_arlso.loc[:, \"almacenamiento_hm3\"] = pd.to_numeric(df_arlso[\"almacenamiento_hm3\"], errors='coerce')\n",
    "df_arlso.loc[:, \"fecha\"] = pd.to_datetime(df_arlso[\"fecha\"], format=\"mixed\", errors='coerce')\n",
    "\n",
    "# Eliminar filas con fechas o almacenamiento nulos\n",
    "df_arlso = df_arlso.dropna(subset=['fecha', 'almacenamiento_hm3'])\n",
    "\n",
    "# Ordenar por fecha\n",
    "df_arlso = df_arlso.sort_values('fecha').reset_index(drop=True)\n",
    "\n",
    "#Eliminar la columna clave (todos los valores son iguales)\n",
    "df_arlso.drop(\"clave\", axis=1, inplace=True)\n",
    "\n",
    "print(f\"Registros de la Presa ARLSO: {len(df_arlso)}\")\n",
    "print(f\"Rango de fechas: {df_arlso['fecha'].min()} a {df_arlso['fecha'].max()}\")\n",
    "print(f\"\\nPrimeros registros:\")\n",
    "display(df_arlso.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Estadísticas descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:00:09.685375Z",
     "iopub.status.busy": "2025-10-16T05:00:09.685375Z",
     "iopub.status.idle": "2025-10-16T05:00:09.692891Z",
     "shell.execute_reply": "2025-10-16T05:00:09.692891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas descriptivas del almacenamiento (hm³):\n",
      "count     24631.00\n",
      "unique     3823.00\n",
      "top           0.01\n",
      "freq       2415.00\n",
      "Name: almacenamiento_hm3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Estadísticas descriptivas del almacenamiento (hm³):\")\n",
    "print(df_arlso['almacenamiento_hm3'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Guardar datos en CSV\n",
    "\n",
    "Exportamos los datos limpios de la presa a un archivo CSV para uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:00:09.695007Z",
     "iopub.status.busy": "2025-10-16T05:00:09.695007Z",
     "iopub.status.idle": "2025-10-16T05:00:09.764781Z",
     "shell.execute_reply": "2025-10-16T05:00:09.764781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Archivo guardado exitosamente: c:\\Users\\DELL\\Documents\\Areas\\MCD\\1S\\Ingeniería de Características\\ingesta de datos\\arhbpalr\\arhbpalr\\data\\raw\\datos_presa_arlso.csv\n",
      "  - Registros: 24631\n",
      "  - Columnas: ['fecha', 'almacenamiento_hm3']\n",
      "  - Tamaño: 644.04 KB\n"
     ]
    }
   ],
   "source": [
    "# Guardar el DataFrame en CSV en la carpeta data/raw según estándares Cookiecutter\n",
    "output_file = data_dir / 'datos_presa_arlso.csv'\n",
    "df_arlso.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✓ Archivo guardado exitosamente: {output_file}\")\n",
    "print(f\"  - Registros: {len(df_arlso)}\")\n",
    "print(f\"  - Columnas: {list(df_arlso.columns)}\")\n",
    "print(f\"  - Tamaño: {os.path.getsize(output_file) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Limpieza: eliminar archivos temporales\n",
    "\n",
    "Removemos los archivos CSV temporales creados durante el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:00:09.766966Z",
     "iopub.status.busy": "2025-10-16T05:00:09.766966Z",
     "iopub.status.idle": "2025-10-16T05:00:09.773986Z",
     "shell.execute_reply": "2025-10-16T05:00:09.773482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Directorio temporal 'temp_csv' eliminado\n",
      "\n",
      "==================================================\n",
      "PROCESO COMPLETADO\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Eliminar archivos temporales\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(temp_dir):\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f\"✓ Directorio temporal '{temp_dir}' eliminado\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROCESO COMPLETADO\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
