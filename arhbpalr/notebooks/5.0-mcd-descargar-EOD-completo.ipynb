{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57bf9e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stream_unzip in c:\\python312\\lib\\site-packages (0.0.99)\n",
      "Requirement already satisfied: pycryptodome>=3.10.1 in c:\\python312\\lib\\site-packages (from stream_unzip) (3.23.0)\n",
      "Requirement already satisfied: stream-inflate>=0.0.12 in c:\\python312\\lib\\site-packages (from stream_unzip) (0.0.42)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install stream_unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379bda28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from stream_unzip import stream_unzip\n",
    "import io\n",
    "import csv\n",
    "import zipfile\n",
    "import struct\n",
    "import zlib\n",
    "import os\n",
    "\n",
    "url = \"https://hosted-datasets.gbif.org/eBird/2024-eBird-dwca-1.0.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f09d287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'meta.xml' 2493\n",
      "ERROR: UnfinishedIterationError \n"
     ]
    }
   ],
   "source": [
    "with requests.get(url, stream=True) as r:\n",
    "    try:\n",
    "        for filename, filesize, file_stream in stream_unzip(r.raw):\n",
    "            print(filename, filesize)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR:\", type(e).__name__, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57b0898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Content-Type: application/zip\n",
      "Accept-Ranges: bytes\n",
      "Content-Encoding: None\n"
     ]
    }
   ],
   "source": [
    "r = requests.head(url, allow_redirects=True) # Para saber si acepta la descarga en stream\n",
    "print(\"Status:\", r.status_code)\n",
    "print(\"Content-Type:\", r.headers.get(\"Content-Type\"))\n",
    "print(\"Accept-Ranges:\", r.headers.get(\"Accept-Ranges\"))\n",
    "print(\"Content-Encoding:\", r.headers.get(\"Content-Encoding\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4050c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5242880 bytes fetched\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(url, headers={\"Range\": \"bytes=-5242880\"})\n",
    "open(\"tail.zip\", \"wb\").write(r.content)\n",
    "print(len(r.content), \"bytes fetched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faa690da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries: ['meta.xml', 'eml.xml', 'eod_2024.csv']\n"
     ]
    }
   ],
   "source": [
    "with open(\"tail.zip\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Look for central directory signatures\n",
    "pos = data.find(b\"PK\\x01\\x02\")\n",
    "entries = []\n",
    "while pos != -1:\n",
    "    fn_len = int.from_bytes(data[pos+28:pos+30], \"little\")\n",
    "    extra_len = int.from_bytes(data[pos+30:pos+32], \"little\")\n",
    "    comment_len = int.from_bytes(data[pos+32:pos+34], \"little\")\n",
    "    filename = data[pos+46:pos+46+fn_len].decode(errors=\"ignore\")\n",
    "    header_offset = int.from_bytes(data[pos+42:pos+46], \"little\")\n",
    "    entries.append((filename, header_offset))\n",
    "    pos = data.find(b\"PK\\x01\\x02\", pos+1)\n",
    "\n",
    "print(\"Found entries:\", [e[0] for e in entries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf50ebf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail.zip has been deleted.\n",
      "{'filename': 'eod_2024.csv', 'offset': 3377, 'comp_size': 4294967295, 'uncomp_size': 4294967295}\n"
     ]
    }
   ],
   "source": [
    "with open(\"tail.zip\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "entries = []\n",
    "pos = data.find(b\"PK\\x01\\x02\")\n",
    "while pos != -1:\n",
    "    # Read key fields\n",
    "    comp_size = int.from_bytes(data[pos+20:pos+24], \"little\")\n",
    "    uncomp_size = int.from_bytes(data[pos+24:pos+28], \"little\")\n",
    "    fn_len = int.from_bytes(data[pos+28:pos+30], \"little\")\n",
    "    extra_len = int.from_bytes(data[pos+30:pos+32], \"little\")\n",
    "    comment_len = int.from_bytes(data[pos+32:pos+34], \"little\")\n",
    "    header_offset = int.from_bytes(data[pos+42:pos+46], \"little\")\n",
    "    filename = data[pos+46:pos+46+fn_len].decode(errors=\"ignore\")\n",
    "    entries.append({\n",
    "        \"filename\": filename,\n",
    "        \"offset\": header_offset,\n",
    "        \"comp_size\": comp_size,\n",
    "        \"uncomp_size\": uncomp_size\n",
    "    })\n",
    "    pos = data.find(b\"PK\\x01\\x02\", pos + 1)\n",
    "\n",
    "# Find your CSV entry\n",
    "csv_entry = next(e for e in entries if e[\"filename\"].endswith(\"eod_2024.csv\"))\n",
    "file_path = \"tail.zip\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"{file_path} has been deleted.\")\n",
    "else:\n",
    "    print(f\"{file_path} does not exist.\")\n",
    "print(csv_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eef24ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real sizes: 71515376935 556156633708\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(url, headers={\"Range\": \"bytes=3377-6000\"})\n",
    "data = r.content\n",
    "\n",
    "# Local file header starts with PK\\x03\\x04\n",
    "lfh_sig = data.find(b\"PK\\x03\\x04\")\n",
    "comp_method = int.from_bytes(data[lfh_sig+8:lfh_sig+10], \"little\")\n",
    "fn_len = int.from_bytes(data[lfh_sig+26:lfh_sig+28], \"little\")\n",
    "extra_len = int.from_bytes(data[lfh_sig+28:lfh_sig+30], \"little\")\n",
    "\n",
    "extra = data[lfh_sig+30+fn_len : lfh_sig+30+fn_len+extra_len]\n",
    "# Parse ZIP64 extra field (0x0001)\n",
    "if b\"\\x01\\x00\" in extra:\n",
    "    i = extra.index(b\"\\x01\\x00\")\n",
    "    real_uncomp, real_comp = struct.unpack_from(\"<QQ\", extra, i+4)\n",
    "    print(\"Real sizes:\", real_comp, real_uncomp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc08640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_5508\\1346995100.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  output_csv = \"..\\data\\interim\\ebirdSonora.csv\"\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_5508\\1346995100.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  output_csv = \"..\\data\\interim\\ebirdSonora.csv\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m headers = {\u001b[33m\"\u001b[39m\u001b[33mRange\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbytes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}\n\u001b[32m     44\u001b[39m r = requests.get(url, headers=headers, stream=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m8192\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\urllib3\\response.py:1043\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1046\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\urllib3\\response.py:935\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    933\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\urllib3\\response.py:862\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    859\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    863\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    864\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    865\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    870\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    871\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    872\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\urllib3\\response.py:845\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    844\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "output_csv = \"..\\data\\raw\\ebirdSonora.csv\"\n",
    "\n",
    "local_header_offset = csv_entry['offset']\n",
    "compressed_size = real_comp  \n",
    "chunk_size = 100_000_000       # 100 MB chunks\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Helper to parse local header\n",
    "# -----------------------------\n",
    "def parse_local_file_header(data):\n",
    "    assert data[:4] == b'PK\\x03\\x04'\n",
    "    comp_method = int.from_bytes(data[8:10], \"little\")\n",
    "    fn_len = int.from_bytes(data[26:28], \"little\")\n",
    "    extra_len = int.from_bytes(data[28:30], \"little\")\n",
    "    header_len = 30 + fn_len + extra_len\n",
    "    return header_len, comp_method\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Download local header first\n",
    "# -----------------------------\n",
    "r = requests.get(url, headers={\"Range\": f\"bytes={local_header_offset}-{local_header_offset + 1024}\"})\n",
    "data = r.content\n",
    "header_len, comp_method = parse_local_file_header(data)\n",
    "\n",
    "if comp_method != 8:\n",
    "    raise NotImplementedError(\"Only deflate-compressed files are supported\")\n",
    "\n",
    "compressed_start = local_header_offset + header_len\n",
    "decompressor = zlib.decompressobj(-zlib.MAX_WBITS)  # raw DEFLATE\n",
    "buffer = b\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Open output CSV\n",
    "# -----------------------------\n",
    "with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as fout:\n",
    "    writer = csv.writer(fout)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Step 5: Stream compressed data in chunks\n",
    "    # -----------------------------\n",
    "    for start in range(compressed_start, compressed_start + compressed_size, chunk_size):\n",
    "        end = min(start + chunk_size - 1, compressed_start + compressed_size - 1)\n",
    "        headers = {\"Range\": f\"bytes={start}-{end}\"}\n",
    "        r = requests.get(url, headers=headers, stream=True)\n",
    "\n",
    "        for chunk in r.iter_content(8192):\n",
    "            if not chunk:\n",
    "                continue\n",
    "            decompressed = decompressor.decompress(chunk)\n",
    "            buffer += decompressed\n",
    "\n",
    "            # Split complete lines\n",
    "            while b\"\\n\" in buffer:\n",
    "                line, buffer = buffer.split(b\"\\n\", 1)\n",
    "                row = line.decode(\"utf-8\").split(\",\")\n",
    "\n",
    "                # Filter by row[11] == 'Sonora'\n",
    "                if len(row) > 11 and row[11] == \"Sonora\":\n",
    "                    writer.writerow(row)\n",
    "\n",
    "    # Process any remaining data\n",
    "    if buffer:\n",
    "        row = buffer.decode(\"utf-8\").split(\",\")\n",
    "        if len(row) > 11 and row[11] == \"Sonora\":\n",
    "            writer.writerow(row)\n",
    "\n",
    "print(f\"Filtered rows written to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed0c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\interim\\ebirdSonora.csv has been zipped into ..\\data\\interim\\ebirdSonora.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_5508\\3234402322.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  zip_file = \"..\\data\\interim\\ebirdSonora.zip\"\n"
     ]
    }
   ],
   "source": [
    "zip_file = \"..\\data\\raw\\ebirdSonora.zip\"\n",
    "\n",
    "# Create a zip file containing the CSV\n",
    "with zipfile.ZipFile(zip_file, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "    zf.write(output_csv, arcname=output_csv)  # arcname keeps the filename inside the zip\n",
    "\n",
    "print(f\"{output_csv} has been zipped into {zip_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db632200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\interim\\ebirdSonora.csv has been deleted after zipping.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(output_csv):\n",
    "    os.remove(output_csv)\n",
    "    print(f\"{output_csv} has been deleted after zipping.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
